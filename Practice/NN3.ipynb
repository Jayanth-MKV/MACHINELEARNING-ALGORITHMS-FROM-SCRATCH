{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNlTb0WbSZgTZf13/JEyQcO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eOKH2d7Gu1M","executionInfo":{"status":"ok","timestamp":1675057233306,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jayanth MKV","userId":"04368715744450558786"}},"outputId":"63f0b826-f6bf-4541-d611-95717d87288c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[array([[ 6.84054358e-01,  6.04024326e-01, -6.06895041e-04],\n","       [-9.91593726e-01,  7.22775342e-01,  4.19016986e-01],\n","       [ 9.27142785e-01,  6.02030646e-01, -2.80442570e-02]]), array([[-0.89507884,  0.20505805,  0.31282069, -0.1855647 ],\n","       [-0.09551729, -0.13902178, -0.59012892, -0.38542134],\n","       [-0.58159621,  0.95490446, -0.81662792,  0.33998702]]), array([[ 0.48195119],\n","       [ 0.40591827],\n","       [-0.44749464],\n","       [-0.20236251]])]\n","epochs: 0\n","[0 0] [[-0.06151797]]\n","[0 1] [[-0.09348674]]\n","[1 0] [[0.50427212]]\n","[1 1] [[0.25898027]]\n"]}],"source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1.0/(1.0 + np.exp(-x))\n","\n","def sigmoid_prime(x):\n","    return sigmoid(x)*(1.0-sigmoid(x))\n","\n","def tanh(x):\n","    return np.tanh(x)\n","\n","def tanh_prime(x):\n","    return 1.0 - x**2\n","\n","\n","class NeuralNetwork:\n","\n","    def __init__(self, layers, activation='tanh'):\n","        if activation == 'sigmoid':\n","            self.activation = sigmoid\n","            self.activation_prime = sigmoid_prime\n","        elif activation == 'tanh':\n","            self.activation = tanh\n","            self.activation_prime = tanh_prime\n","\n","        # Set weights\n","        self.weights = []\n","        # layers = [2,2,1]\n","        # range of weight values (-1,1)\n","        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n","        for i in range(1, len(layers) - 1):\n","            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n","            self.weights.append(r)\n","        # output layer - random((2+1, 1)) : 3 x 1\n","        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n","        self.weights.append(r)\n","        print(self.weights)\n","\n","    def fit(self, X, y, learning_rate=0.2, epochs=1):\n","        # Add column of ones to X\n","        # This is to add the bias unit to the input layer\n","        ones = np.atleast_2d(np.ones(X.shape[0]))\n","        X = np.concatenate((ones.T, X), axis=1)\n","         \n","        for k in range(epochs):\n","            i = np.random.randint(X.shape[0])\n","            a = [X[i]]\n","\n","            for l in range(len(self.weights)):\n","                    dot_value = np.dot(a[l], self.weights[l])\n","                    activation = self.activation(dot_value)\n","                    a.append(activation)\n","            # output layer\n","            error = y[i] - a[-1]\n","            deltas = [error * self.activation_prime(a[-1])]\n","\n","            # we need to begin at the second to last layer \n","            # (a layer before the output layer)\n","            for l in range(len(a) - 2, 0, -1): \n","                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n","\n","            # reverse\n","            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n","            deltas.reverse()\n","\n","            # backpropagation\n","            # 1. Multiply its output delta and input activation \n","            #    to get the gradient of the weight.\n","            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n","            for i in range(len(self.weights)):\n","                layer = np.atleast_2d(a[i])\n","                delta = np.atleast_2d(deltas[i])\n","                self.weights[i] += learning_rate * layer.T.dot(delta)\n","\n","            if k % 10000 == 0: print('epochs:', k)\n","\n","    def predict(self, x): \n","        # print(np.ones(1).T, np.array(x))\n","        # print((np.ones(1).reshape(1,1)),(np.ones(1).reshape(1,1)).shape)\n","        # print(np.array(x),np.array(x).shape)\n","        a = np.concatenate((np.ones(1).reshape(1,1), np.array(x).reshape(1,-1)), axis=1)      \n","        for l in range(0, len(self.weights)):\n","            a = self.activation(np.dot(a, self.weights[l]))\n","        return a\n","\n","if __name__ == '__main__':\n","\n","    nn = NeuralNetwork([2,2,3,1])\n","    X = np.array([[0, 0],\n","                  [0, 1],\n","                  [1, 0],\n","                  [1, 1]])\n","    y = np.array([0, 1, 1, 0])\n","    nn.fit(X, y)\n","    for e in X:\n","        print(e,nn.predict(e))"]}]}