{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4gpeWhqCfS0dWBBN3mgnr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"T83TtJQI27MZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["[2,2,1][:1]\n","layers=[2,2,1]\n","layers = [print(n_neurons,n_inputs) for n_neurons, n_inputs in zip(layers, layers[:-1])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnvg5PXlp7G_","executionInfo":{"status":"ok","timestamp":1674662468103,"user_tz":-330,"elapsed":5,"user":{"displayName":"Jayanth MKV","userId":"04368715744450558786"}},"outputId":"70c06dd4-a547-4e16-ba40-9125a85f64b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnhpYNMq2gOD"},"outputs":[],"source":["class ActivationFunction:\n","    def __init__(self, func, derivative, name):\n","        self.func = func\n","        self.derivative = derivative\n","        self.name = name\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","sigmoid_activation = ActivationFunction(sigmoid, sigmoid_derivative, 'sigmoid')\n","\n"]},{"cell_type":"code","source":["class NeuralNetwork:\n","    def __init__(self, layers, activation_function):\n","        self.layers = [Layer(n_neurons, activation_function, n_inputs) for n_neurons, n_inputs in zip(layers, layers[:-1])]\n","        # self.layers = [Layer(n_neurons, activation_function) for n_neurons in layers]\n","        self.activation_function = activation_function\n","\n","    def forward(self, inputs):\n","        for layer in self.layers:\n","            inputs = layer.forward(inputs)\n","        return inputs\n","\n","    # def backward(self, inputs, expected_output, learning_rate):\n","    #     # propagate the error through the layers in reverse order\n","    #     for i in range(len(self.layers) - 1, -1, -1):\n","    #         layer = self.layers[i]\n","    #         inputs = layer.backward(inputs, expected_output, learning_rate, self.activation_function)\n","    \n","    def backward(self, inputs, expected_output, learning_rate):\n","        error = expected_output - self.forward(inputs)\n","        for i in reversed(range(len(self.layers))):\n","            layer = self.layers[i]\n","            error = layer.backward(error, learning_rate, self.activation_function)\n","\n","    def train(self, X, y, learning_rate, epochs):\n","        for i in range(epochs):\n","            for j, inputs in enumerate(X):\n","                output = self.forward(inputs)\n","                self.backward(inputs, y[j], learning_rate)"],"metadata":{"id":"sozPtC3q2p7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Layer:\n","    def __init__(self, n_neurons, activation_function, n_inputs):\n","        self.neurons = [Neuron(activation_function, n_inputs) for _ in range(n_neurons)]\n","\n","    def forward(self, inputs):\n","        outputs = []\n","        for neuron in self.neurons:\n","            outputs.append(neuron.forward(inputs))\n","        return outputs\n","\n","    def backward(self, inputs, expected_output, learning_rate, activation_function):\n","        print(expected_output)\n","        print(expected_output.shape)\n","        print(type(expected_output))\n","        errors = []\n","        expected_output = np.reshape(expected_output, (len(expected_output), 1))\n","        print(expected_output)\n","        print(expected_output.shape)\n","        print(type(expected_output))\n","        for i, neuron in enumerate(self.neurons):\n","            error = expected_output[i] - neuron.output\n","            errors.append(error)\n","            neuron.backward(error, learning_rate, activation_function,inputs)\n","\n"],"metadata":{"id":"waR6eZvf2qbK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Neuron:\n","    def __init__(self, activation_function, n_inputs):\n","        self.weights = np.random.randn(n_inputs)\n","        self.bias = np.random.randn()\n","        self.output = None\n","        self.activation_function = activation_function\n","\n","    def forward(self, inputs):\n","        weighted_sum = np.dot(inputs, self.weights) + self.bias\n","        self.output = self.activation_function.func(weighted_sum)\n","        return self.output\n","\n","    def backward(self, error, learning_rate, activation_function,inputs):\n","        # update the weights and bias\n","        derivative = activation_function.derivative(self.output)\n","        self.weights += learning_rate * error * derivative * inputs\n","        self.bias += learning_rate * error * derivative\n"],"metadata":{"id":"I9YXav-V20qL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# # create the neural network with 2 input neurons, 2 hidden neurons, and 1 output neuron\n","# nn = NeuralNetwork([2, 2, 1], sigmoid_activation)\n","\n","# # create the dataset with input and output values\n","# X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n","# y = np.array([[1], [0], [0], [0]])\n","\n","# # train the network\n","# nn.train(X, y, learning_rate=0.1, epochs=1000)\n","\n","# # make a prediction for the first input in the dataset\n","# inputs = X[0]\n","# output = nn.forward(inputs)\n","# print(output) # [0.5]\n"],"metadata":{"id":"OB5kutxr22rR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","class Neuron:\n","    def __init__(self, n_inputs, activation_function):\n","        self.weights = np.random.random(n_inputs)\n","        self.bias = np.random.randn()\n","        self.output = None\n","        self.activation_function = activation_function\n","\n","    def forward(self, inputs):\n","        z = np.dot( self.weights,inputs) + self.bias\n","        self.output = self.activation_function(z)\n","        return self.output\n","\n","    def backward(self, error, learning_rate, activation_function_derivative,inputs):\n","        delta = error * activation_function_derivative(self.output)\n","        self.weights -= learning_rate * delta * inputs\n","        self.bias -= learning_rate * delta\n","\n","class Layer:\n","    def __init__(self, n_neurons, n_inputs, activation_function):\n","        self.neurons = [Neuron(n_inputs, activation_function) for _ in range(n_neurons)]\n","        self.output = None\n","\n","    def forward(self, inputs):\n","        self.inputs = inputs\n","        self.output = np.array([neuron.forward(inputs) for neuron in self.neurons])\n","        return self.output\n","\n","    def backward(self, error, learning_rate, activation_function, activation_function_derivative):\n","        errors = []\n","        error = np.dot(error, np.transpose(self.weights))\n","        for i, neuron in enumerate(self.neurons):\n","            errors.append(error[i] * activation_function_derivative(neuron.output))\n","            neuron.backward(error[i], learning_rate, activation_function_derivative, self.inputs)\n","        return errors\n","\n","class NeuralNetwork:\n","    def __init__(self, architecture, activation_function, activation_function_derivative):\n","        self.layers = [Layer(n_neurons, n_inputs, activation_function) for n_neurons, n_inputs in zip(architecture[:-1], architecture[1:])]\n","        self.output_layer = Layer(architecture[-1], architecture[-2], activation_function)\n","        self.activation_function = activation_function\n","        self.activation_function_derivative = activation_function_derivative\n","\n","    def forward(self, inputs):\n","        for layer in self.layers:\n","            inputs = layer.forward(inputs)\n","        return self.output_layer.forward(inputs)\n","\n","    def backward(self, inputs, expected_output, learning_rate):\n","        error = expected_output - self.forward(inputs)\n","        for i in reversed(range(len(self.layers))):\n","            layer = self.layers[i]\n","            error = layer.backward(error, learning_rate, self.activation_function, self.activation_function_derivative)\n","            self.output_layer.backward(error, learning_rate, self.activation_function, self.activation_function_derivative)\n","\n","    def train(self, inputs, expected_output, learning_rate, epochs):\n","        for _ in range(epochs):\n","            for i in range(len(inputs)):\n","                self.forward(inputs[i])\n","                self.backward(inputs[i], expected_output[i], learning_rate)\n","\n","    def predict(self, inputs):\n","        return self.forward(inputs)\n"],"metadata":{"id":"UDz2O4hDvoMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the neural network with 2 input neurons, 2 hidden neurons, and 1 output neuron\n","nn = NeuralNetwork([2, 2, 1], sigmoid,sigmoid_derivative)\n","\n","# create the XOR dataset\n","X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n","y = np.array([[0], [1], [1], [0]])\n","\n","# train the network\n","nn.train(X, y, learning_rate=0.1, epochs=10000)\n","\n","# make predictions for the XOR dataset\n","for inputs, expected_output in zip(X, y):\n","    output = nn.forward(inputs)\n","    print(f'Inputs: {inputs}, Output: {output}, Expected Output: {expected_output}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"iZTJwZbq23aA","executionInfo":{"status":"error","timestamp":1674664195830,"user_tz":-330,"elapsed":16,"user":{"displayName":"Jayanth MKV","userId":"04368715744450558786"}},"outputId":"d5f12c6e-af03-4774-f52d-c747b5aeb99b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-15b398820bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# make predictions for the XOR dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-7bf493eefded>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, expected_output, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-7bf493eefded>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-7bf493eefded>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-7bf493eefded>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-7bf493eefded>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,) and (2,) not aligned: 1 (dim 0) != 2 (dim 0)"]}]}]}