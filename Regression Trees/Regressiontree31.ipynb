{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMy6ICax+S3zT9veoVgzbIt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mvi4WHuEp2Gm"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import graphviz"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6ehfqgZW9Cm","executionInfo":{"status":"ok","timestamp":1679254377380,"user_tz":-330,"elapsed":30738,"user":{"displayName":"Jayanth MKV","userId":"04368715744450558786"}},"outputId":"51cf7f21-e62c-49af-9523-2ffc9a5b8556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path=\"/content/drive/MyDrive/MachineLearning/13-03-2023/airfoil_self_noise.csv\""],"metadata":{"id":"RIN1NO8-W9Uk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data=pd.read_csv(path)\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"jHCTLV6tXCWO","executionInfo":{"status":"ok","timestamp":1679254379209,"user_tz":-330,"elapsed":1833,"user":{"displayName":"Jayanth MKV","userId":"04368715744450558786"}},"outputId":"bceb0348-d0a5-4c38-b8c8-dad0baa7e94b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        x0    x1      x2    x3        x4        y\n","0      800   0.0  0.3048  71.3  0.002663  126.201\n","1     1000   0.0  0.3048  71.3  0.002663  125.201\n","2     1250   0.0  0.3048  71.3  0.002663  125.951\n","3     1600   0.0  0.3048  71.3  0.002663  127.591\n","4     2000   0.0  0.3048  71.3  0.002663  127.461\n","...    ...   ...     ...   ...       ...      ...\n","1498  2500  15.6  0.1016  39.6  0.052849  110.264\n","1499  3150  15.6  0.1016  39.6  0.052849  109.254\n","1500  4000  15.6  0.1016  39.6  0.052849  106.604\n","1501  5000  15.6  0.1016  39.6  0.052849  106.224\n","1502  6300  15.6  0.1016  39.6  0.052849  104.204\n","\n","[1503 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-d98da00b-f932-4fe7-a15c-35bc3cbc9d3d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x0</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>x3</th>\n","      <th>x4</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0.0</td>\n","      <td>0.3048</td>\n","      <td>71.3</td>\n","      <td>0.002663</td>\n","      <td>126.201</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000</td>\n","      <td>0.0</td>\n","      <td>0.3048</td>\n","      <td>71.3</td>\n","      <td>0.002663</td>\n","      <td>125.201</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1250</td>\n","      <td>0.0</td>\n","      <td>0.3048</td>\n","      <td>71.3</td>\n","      <td>0.002663</td>\n","      <td>125.951</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1600</td>\n","      <td>0.0</td>\n","      <td>0.3048</td>\n","      <td>71.3</td>\n","      <td>0.002663</td>\n","      <td>127.591</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2000</td>\n","      <td>0.0</td>\n","      <td>0.3048</td>\n","      <td>71.3</td>\n","      <td>0.002663</td>\n","      <td>127.461</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>2500</td>\n","      <td>15.6</td>\n","      <td>0.1016</td>\n","      <td>39.6</td>\n","      <td>0.052849</td>\n","      <td>110.264</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>3150</td>\n","      <td>15.6</td>\n","      <td>0.1016</td>\n","      <td>39.6</td>\n","      <td>0.052849</td>\n","      <td>109.254</td>\n","    </tr>\n","    <tr>\n","      <th>1500</th>\n","      <td>4000</td>\n","      <td>15.6</td>\n","      <td>0.1016</td>\n","      <td>39.6</td>\n","      <td>0.052849</td>\n","      <td>106.604</td>\n","    </tr>\n","    <tr>\n","      <th>1501</th>\n","      <td>5000</td>\n","      <td>15.6</td>\n","      <td>0.1016</td>\n","      <td>39.6</td>\n","      <td>0.052849</td>\n","      <td>106.224</td>\n","    </tr>\n","    <tr>\n","      <th>1502</th>\n","      <td>6300</td>\n","      <td>15.6</td>\n","      <td>0.1016</td>\n","      <td>39.6</td>\n","      <td>0.052849</td>\n","      <td>104.204</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1503 rows Ã— 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98da00b-f932-4fe7-a15c-35bc3cbc9d3d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d98da00b-f932-4fe7-a15c-35bc3cbc9d3d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d98da00b-f932-4fe7-a15c-35bc3cbc9d3d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["class Node():\n","  def __init__(self, name, value):\n","    self.name = name\n","    self.value = value\n","    self.children = []\n","    self.label=[]\n","        \n","  def add_child(self, node):\n","    self.children.append(node)\n","\n","  def add_label(self, label):\n","    self.label.append(label)\n","\n","  def print_node(self):\n","    print(self.name or self.value)\n","    for i in self.children:\n","      i.print_node()  "],"metadata":{"id":"AyPMlNlvXD_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h12K4nlXrL7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5x8o8T1tvwHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class RegressionTree:\n","    def __init__(self, dataset, target_feature):\n","      # Initialize an empty list of labels for visualization and construct the decision tree\n","        self.root = self.construct(dataset, target_feature)\n","\n","    def construct(self, dataset, target_feature):\n","        # If the dataset is empty, return a leaf node with no value\n","        if len(dataset) == 0:\n","            return Node(None, None)\n","        # If all the values in the target feature are the same, return a leaf node with that value\n","        if len(dataset[target_feature].unique()) == 1:\n","            return Node(None, dataset[target_feature].iloc[0])\n","        # If there are no more features to split on, return a leaf node with the most common value in the target feature\n","        if len(dataset.columns) == 1:\n","            return Node(None, dataset[target_feature].mean())\n","\n","\n","        num_features=len(dataset.columns)-1\n","        # Initialize variables to keep track of the best feature to split on and the highest information gain\n","        best= self.get_best_split(dataset, num_features)\n","        best_feature=dataset.columns[best[\"feature_index\"]]\n","        val=best[\"threshold\"]\n","        # check if information gain is positive\n","        root_node = Node(best_feature, val)\n","        # print(\"II\")\n","\n","        if best[\"var_red\"]>0:\n","          # Create a new root node with the best feature and highest information gain\n","          # Split the dataset into subsets based on the values of the best feature\n","          splits = self.split(dataset, best[\"feature_index\"],val)\n","          # Iterate over the subsets and construct a decision tree for each one\n","          for i, s in enumerate(splits):\n","              # Create a new dataset without the best feature\n","              new_dataset = s.drop(best_feature, axis=1)\n","              # Construct a decision tree for this subset\n","              child = self.construct(new_dataset, target_feature)\n","              # Add the label for this split to the list of labels for the root node\n","              root_node.add_label(str(i))\n","              # Add the child tree as a child of the root node\n","              root_node.add_child(child)\n","        # Return the root node\n","        return root_node\n","\n","\n","    def get_best_split(self, dataset, num_features):\n","        ''' function to find the best split '''\n","        \n","        # dictionary to store the best split\n","        best_split = {}\n","        max_var_red = float(\"inf\")\n","        # loop over all the features\n","        for feature_index in range(num_features):\n","            feature_values = dataset.iloc[:, feature_index]\n","            possible_thresholds = np.unique(feature_values)\n","            # loop over all the feature values present in the data\n","            for threshold in possible_thresholds:\n","                # get current split\n","                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n","                # check if childs are not null\n","                if len(dataset_left)>0 and len(dataset_right)>0:\n","                    y, left_y, right_y = dataset.iloc[:, -1:], dataset_left.iloc[:, -1:], dataset_right.iloc[:, -1:]\n","                    # print(y,left_y,right_y)\n","                    # compute information gain\n","                    curr_var_red = self.SSE(y, left_y, right_y)\n","                    # update the best split if needed\n","                    if curr_var_red<max_var_red:\n","                        best_split[\"feature_index\"] = feature_index\n","                        best_split[\"threshold\"] = threshold\n","                        # best_split[1] = dataset_left\n","                        # best_split[2] = dataset_right\n","                        best_split[\"var_red\"] = curr_var_red\n","                        max_var_red = curr_var_red\n","                        \n","        # return best split\n","        return best_split\n","    \n","    def split(self, dataset, feature_index, threshold):\n","        ''' function to split the data '''\n","        # for r in dataset:\n","        #   print(r)\n","        # print(type(threshold))\n","        # print(dataset.loc[dataset[dataset.columns[feature_index]]<=threshold])\n","        dataset_left = dataset.loc[dataset[dataset.columns[feature_index]]<=threshold]\n","        dataset_right = dataset.loc[dataset[dataset.columns[feature_index]]>threshold]\n","        # print(dataset_left)\n","        return dataset_left, dataset_right\n","    \n","    def SSE(self, parent, l_child, r_child):\n","        ''' function to compute variance reduction '''\n","        reduction = (len(l_child) * np.var(l_child) + len(r_child) * np.var(r_child))\n","        # print(reduction)\n","        return float(reduction)\n","\n","    def predict(self,test):\n","        predictions=[]\n","        for _,row in test.iterrows():\n","          node=self.root\n","          while(node.name):\n","            feature=node.name\n","            val=row[feature]\n","            if val<=node.value:\n","                node=node.children[0]\n","            else:\n","                node=node.children[1]\n","          predictions.append(node.value)\n","        return predictions\n","\n","    # def accuracy(self,actual,predicted):\n","    #     actual=list(actual)\n","    #     predicted=list(predicted)\n","    #     correct=0\n","    #     for i in range(len(actual)):\n","    #       if actual[i]==predicted[i]:\n","    #         correct+=1\n","        \n","    #     return (correct/len(actual))*100\n","\n","\n"],"metadata":{"id":"lrGUHcRHXI2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.iloc[:, :-1]\n","Y = data.iloc[:, -1]\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"],"metadata":{"id":"L8Muxmormwc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg=RegressionTree(data,\"y\")\n"],"metadata":{"id":"nGd8Db27mzEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_pred = reg.predict(X_test) \n","from sklearn.metrics import mean_squared_error\n","np.sqrt(mean_squared_error(Y_test, Y_pred))"],"metadata":{"id":"llzXvZU8xJbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["                    "],"metadata":{"id":"djzIsOD2ydKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XuYWtTROydSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4WDVA2JIydS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p13NU6qGydTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7hjJ5PzLydUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jFpZpEfDydVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L9LZpOxMydWP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BArj3n4ZydXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sPM8u64cydYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6bvD0emAydY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VvwRzNyzydZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dPPXgdddydcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ryE_yIzoyddG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rNRTdRcmydeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MHLnNnMFydf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OHk62m8FydhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xpkFczDpydh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CKQDnElzydiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","class RegressionTree:\n","    \n","    def __init__(self, min_samples_split=2, max_depth=2):\n","        self.min_samples_split = min_samples_split\n","        self.max_depth = max_depth\n","        self.tree = {}\n","        \n","    def fit(self, X, y):\n","        self.tree = self._grow_tree(X, y)\n","        \n","    def _grow_tree(self, X, y, depth=0):\n","        n_samples, n_features = X.shape\n","        n_labels = len(np.unique(y))\n","        \n","        # Stopping criteria\n","        if (n_samples >= self.min_samples_split and\n","            depth <= self.max_depth and\n","            n_labels != 1):\n","            \n","            # Find the best split\n","            feature_idxs = np.random.choice(n_features, 1, replace=False)\n","            best_feature, best_threshold = self._best_split(X, y, feature_idxs)\n","            \n","            # Split the data\n","            left_idxs = X[:, best_feature] < best_threshold\n","            right_idxs = X[:, best_feature] >= best_threshold\n","            \n","            left = self._grow_tree(X[left_idxs], y[left_idxs], depth+1)\n","            right = self._grow_tree(X[right_idxs], y[right_idxs], depth+1)\n","            \n","            return {'feature': best_feature,\n","                    'threshold': best_threshold,\n","                    'left': left,\n","                    'right': right}\n","        \n","        else:\n","            leaf_value = self._leaf_value(y)\n","            return {'leaf_value': leaf_value}\n","    \n","    def _best_split(self, X, y, feature_idxs):\n","        best_gain = -np.inf\n","        split_idx, split_threshold = None, None\n","        \n","        for feature_idx in feature_idxs:\n","            thresholds = np.unique(X[:, feature_idx])\n","            \n","            for threshold in thresholds:\n","                left_idxs = X[:, feature_idx] < threshold\n","                right_idxs = X[:, feature_idx] >= threshold\n","                \n","                if len(y[left_idxs]) > 0 and len(y[right_idxs]) > 0:\n","                    gain = self._split_gain(y, y[left_idxs], y[right_idxs])\n","                    \n","                    if gain > best_gain:\n","                        best_gain = gain\n","                        split_idx = feature_idx\n","                        split_threshold = threshold\n","                        \n","        return split_idx, split_threshold\n","    \n","    def _split_gain(self, parent, left, right):\n","        weighted_parent = len(parent) / (len(left) + len(right))\n","        variance_parent = np.var(parent)\n","        variance_left = np.var(left) if len(left) > 0 else 0\n","        variance_right = np.var(right) if len(right) > 0 else 0\n","        \n","        return weighted_parent * (variance_parent - \n","                                   variance_left - \n","                                   variance_right)\n","    \n","    def _leaf_value(self, y):\n","        return np.mean(y)\n","    \n","    def predict(self, X):\n","        return np.array([self._traverse_tree(x, self.tree) for x in X])\n","    \n","    def _traverse_tree(self, x, node):\n","        if 'leaf_value' in node:\n","            return node['leaf_value']\n","        \n","        if x[node['feature']] < node['threshold']:\n","            return self._traverse_tree(x, node['left'])\n","        else:\n","            return self._traverse_tree(x, node['right'])\n"],"metadata":{"id":"brZH7fEgqFKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"6dmProHM4VtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Generate synthetic data\n","X, y = make_regression(n_samples=100, n_features=5, noise=5, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create a regression tree with max depth of 3\n","tree = RegressionTree(max_depth=3)\n","\n","# Fit the regression tree to the training data\n","tree.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = tree.predict(X_test)\n","\n","# Calculate the mean squared error\n","mse = np.mean((y_test - y_pred)**2)\n","print(f\"Mean Squared Error: {mse:.2f}\")\n","\n","# Plot the true vs predicted values\n","plt.scatter(y_test, y_pred)\n","plt.plot([-200, 200], [-200, 200], 'r--')\n","plt.xlabel(\"True Values\")\n","plt.ylabel(\"Predictions\")\n","plt.show()"],"metadata":{"id":"Op-soM4K4Eu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TBbgtlzX4cok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Pr75fp8mYmbe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ns8fEs6CYmdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def construct(self, dataset, target_feature):\n","    # If the dataset is empty, return a leaf node with no value\n","    if len(dataset) == 0:\n","        return Node(None, None)\n","    # If there are no more features to split on, return a leaf node with the mean value of the target feature\n","    if len(dataset.columns) == 1:\n","        return Node(None, dataset[target_feature].mean())\n","\n","    # Initialize variables to keep track of the best feature to split on and the lowest mean squared error\n","    min_mse = float('inf')\n","    best_feature = None\n","\n","    # Calculate the mean squared error for each feature\n","    for feature in dataset.columns:\n","        # Skip the target feature\n","        if feature == target_feature:\n","            continue\n","        mse = self.mean_squared_error(dataset, feature, target_feature)\n","        # If this feature has a lower mean squared error, update the best feature and the lowest mean squared error\n","        if mse < min_mse:\n","            min_mse = mse\n","            best_feature = feature\n","\n","    # Create a new root node with the best feature and lowest mean squared error\n","    root_node = Node(best_feature, min_mse)\n","    # Split the dataset into subsets based on the values of the best feature\n","    splits = self.splitbycolumn(dataset, best_feature)\n","    # Iterate over the subsets and construct a regression tree for each one\n","    for i, split in splits.items():\n","        # Create a new dataset without the best feature\n","        new_dataset = split.drop(best_feature, axis=1)\n","        # Construct a regression tree for this subset\n","        child = self.construct(new_dataset, target_feature)\n","        # Add the label for this split to the list of labels for the root node\n","        root_node.add_label(str(i))\n","        # Add the child tree as a child of the root node\n","        root_node.add_child(child)\n","    # Return the root node\n","    return root_node\n","\n","def splitbycolumn(self, dataset, feature):\n","    # Create a dictionary to store the splits\n","    split = {}\n","    # Get the unique values of the feature\n","    d = dataset[feature].unique()\n","    # Split the dataset into subsets based on the values of the feature\n","    for val in d:\n","        split[val] = dataset.loc[dataset[feature] == val]\n","    # Return the dictionary of splits\n","    return split"],"metadata":{"id":"azyZKB4yYmh7"},"execution_count":null,"outputs":[]}]}